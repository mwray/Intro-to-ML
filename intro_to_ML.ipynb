{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c8114-1e92-4f27-bd41-21903b9636d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from typing import Callable\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b9f14-966c-41b1-9eea-6c03b4dd3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279678b9-a510-438a-92aa-deb28874e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb7f31-2b41-4e5e-825e-da7d0b68626f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d17312-d57f-4391-b636-65023c688a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d204c-5b06-45e5-9b24-36629656ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6da60a-bca1-44f5-94e1-8a90d07e622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = iris['data'].shape[1]\n",
    "fig, axs = plt.subplots(num_features, num_features)\n",
    "\n",
    "# for every feature in the dataset\n",
    "for i in range(num_features):\n",
    "    # for every feature in the dataset\n",
    "    for j in range(num_features):\n",
    "        # plot out a scatter comparing the results using plt.scatter()\n",
    "        axs[i][j].scatter(iris['data'][:,i], iris['data'][:,j], c = iris['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2613bf1-7328-4a26-a07f-2f6f665e5cc7",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "\n",
    "Let's create a train/test split first by putting 20% of the dataset in the test split, and the rest are training.\n",
    "\n",
    "If we look at the data, it is split into all 0s, then all 1s, then all 2s. So we need to get the indices accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94943d1e-662d-4b26-9b3a-5d9a9fc697c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269226b-124b-4b51-8730-c54933257449",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iris['target']), sum(iris['target'] == 0), sum(iris['target'] == 1), sum(iris['target'] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c757f-5020-4636-8730-909f4e734d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(iris['data'], iris['target'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a34b8-bf58-44c8-9043-14651f7f148f",
   "metadata": {},
   "source": [
    "Have a look at the contents of train_data, test_data, train_labels, and test_labels. These will be the $X$s and $Y$s to train and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889383db-e30f-45d3-a5cf-f16c6768a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the train_data, test_data, train_labels, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab35d3-a740-4a35-a1db-ecb9ad783f79",
   "metadata": {},
   "source": [
    "# Training our First  Model\n",
    "\n",
    "In this section we'll use sci-kit learn to train our first model and evaluate its performance.\n",
    "\n",
    "Let's start with the perceptron, you can find info on the perceptron [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f675d1-81d6-4e79-9a13-93e08956624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a perceptron with the default parameters\n",
    "p_model = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fcda1a-4781-4d8b-82f0-09436271aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the perceptron using the fit method\n",
    "p_model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1e160-727c-4a36-8ccf-cbd51b5b5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring the perceptron using the score method. This returns the accuracy on the training set.\n",
    "p_model.score(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f6d1d-2855-4fb4-9fd4-ee555bf801d2",
   "metadata": {},
   "source": [
    "The above cell gives us the accuracy as a value between 0 and 1 on the training set, but this doesn't represent good perfomance as we have seen this data before. To show how well we generalise, we will now score the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06324e8-ef4f-47ee-aba1-8ff663a8f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the perceptron on the test set using the .score method and the test_data/test_labels.\n",
    "p_model.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0e38d-c06a-4d84-a829-eefbede3269d",
   "metadata": {},
   "source": [
    "# Training our Second Model\n",
    "\n",
    "We'll now look at our second model, the Support Vector Machine. You can find information about the SVM [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC).\n",
    "\n",
    "In the same way, we'll train the SVM and then evaluate it on the test set and compare its performance with the perceptron that we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466db80-fad2-40db-9329-44ecc761a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SVC, create an instance of the SVM\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73405a-78fd-4378-9ace-190166f5f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fit to train the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32a2ed-f989-49dd-bb33-c2fac97aa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to test the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8719d3d-8284-40de-910f-14b9faaeed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score to test the model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc3c28-784a-45ed-9346-dba43432a829",
   "metadata": {},
   "source": [
    "# Training our Third Model\n",
    "\n",
    "We'll now look at our final model. This will be a Multi Layer Perceptron which extends the Perceptron with multiple layers. This is a deep learning classifier (a more powerful type of model that generally requires a lot of data). You can find more information [here](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a311918-3b6e-41ff-b5d9-6ef738a8e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d27c7-9cff-464a-9106-7d3c14f48048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the fit method, train the model on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8962cfc-8034-491e-ad6a-6fd06378f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the score method, evaluate the model on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aeaa6d-dd8f-48e5-9121-443d224b4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the score method, evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224d4bc-62ec-416c-a16a-394a1ebedc19",
   "metadata": {},
   "source": [
    "# Comparing our Models\n",
    "\n",
    "You may have noticed if you re-generate your dataset that the results change, or that you are getting very different results to your peers. This is because we may be generating an easier/harder test set. We can get around this by doing multiple runs and then averaging our performance. We will use this to check our actual performance for each of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dfcb3-18b1-4fc7-974a-2a0d01de980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline_tests(model_func: Callable, data: ArrayLike, labels: ArrayLike, num_iter: int=1000):\n",
    "    \"\"\" Runs a number of baseline tests with each test creating a random train/test split of 0.2\n",
    "\n",
    "    Parameters:\n",
    "    model_func (function): function which is used to create a ML model\n",
    "    data (array-like): array of all data elements\n",
    "    labels (array-like): array of labels for the data\n",
    "    num_iter (int): number of iterations to run\n",
    "\n",
    "    Returns:\n",
    "    float: average score of all runs\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in range(num_iter):\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(iris['data'], iris['target'], test_size=0.2)\n",
    "        model = model_func()\n",
    "        model.fit(train_data, train_labels)\n",
    "        scores.append(model.score(test_data, test_labels))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def get_perceptron():\n",
    "    return Perceptron()\n",
    "    \n",
    "def get_svm():\n",
    "    #Add code for returning an SVM model\n",
    "    return None\n",
    "    \n",
    "def get_mlp():\n",
    "    #Add code for returning an SVM model\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112f8f3-157c-4e40-8a51-ef2974c5c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = (iris['data'] - iris['data'].mean(axis=0)) / iris['data'].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f0532-fc1d-4c60-a23e-95b3f6267219",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline_tests(get_perceptron, iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef812985-dc7d-44ff-8791-95651935e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_baseline_tests(get_svm, iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcfe23-5653-4e03-8eb0-c603674a2666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_baseline_tests(get_mlp, iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc146a-0a1a-4b31-ac2c-043b1be38be7",
   "metadata": {},
   "source": [
    "## Improving our Results\n",
    "\n",
    "From looking at the webpages for each of the model types, these have lots of parameters that we could choose from, different from their default values.\n",
    "These are known as hyperparameters and can change the performance of the model by a large amount.\n",
    "\n",
    "Try playing with these parameters for the model and see if you can beat the high scores! Each of the doc pages have some ideas in the example codes, or ask about any potential combinations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
