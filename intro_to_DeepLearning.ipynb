{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first neural network\n",
    "\n",
    "In this lab session we aim to accomplish the following:\n",
    "\n",
    "- Show you the basics of PyTorch\n",
    "- Introduce the implementation of a multilayer perceptron/fully connected deep network.\n",
    "- Train the network on an image dataset\n",
    "\n",
    "### Contents\n",
    "1. [Iris Flower Dataset - A 3-way classification problem](#Iris-Flower-Dataset)\n",
    "2. [Colaboratory notebooks](#Colaboratory-notebooks)\n",
    "3. [Intro to PyTorch](#PyTorch-Intro)\n",
    "4. [Your first DNN](#Building-Your-First-Fully-Connected-Network)\n",
    "5. [Porting the network to a script and running on BC4](#Porting-Your-Network-To-BC4)\n",
    "6. [Logging metrics with TensorBoard](#Logging-Performance-Metrics)\n",
    "7. [Optional Extension: Implementing library functions](#Optional-Extension:-Implementing-library-functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Dataset\n",
    "\n",
    "Our network is designed to operate on images from CIFAR-10, a dataset containing 60,000 RGB images, each 32 $\\times$ 32 in resolution, split into 50,000 images for training and 10,000 images for testing. \n",
    "\n",
    "There are 10 classes with 6,000 examples per class. Some examples of each class can be seen in the diagram below:\n",
    "\n",
    "<img alt=\"CIFAR-10 examples\" src=\"./media/cifar10.png\" style=\"max-height: 500px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## PyTorch Intro\n",
    "\n",
    "In this section we will introduce you in a hands on way to PyTorch. You can check that you get the answers listed in comments at the bottom of each cell in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a lot like numpy, it has a notion of an N-dimensional array like in numpy, but it is instead called a tensor. Tensors generalise scalar, vectors, and matrices. A scalar is a 0D tensor, a vector is a 1D tensor, and a matrix is a 2D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import torchvision.datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "array_np = np.array([[1, 2, 3],\n",
    "                     [4, 5, 6]])\n",
    "array_pytorch = torch.tensor([[1, 2, 3],\n",
    "                              [4, 5, 6]])\n",
    "print(array_np)\n",
    "print(array_pytorch)\n",
    "\n",
    "# OUTPUT\n",
    "# [[1 2 3]\n",
    "#  [4 5 6]]\n",
    "# tensor([[1, 2, 3],\n",
    "#         [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll demonstrate some of the operations defined on tensors. Check out the docs for [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) and [`torch`](https://pytorch.org/docs/stable/torch.html) for details. (You can click on each to find out more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "y = torch.tensor([4, 5, 6], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape  # what are the dimensions of the tensor?\n",
    "\n",
    "# OUTPUT\n",
    "# torch.Size([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dim()  # how many dimensions does the tensor have?\n",
    "\n",
    "# OUTPUT\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x + y # + performs elementwise addition\n",
    "\n",
    "# OUTPUT\n",
    "# tensor([5., 7., 9.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * y  # * performs elementwise multiplication \n",
    "\n",
    "# OUTPUT\n",
    "# tensor([ 4., 10., 18.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x / y  # / performs elementwise division\n",
    "\n",
    "# OUTPUT\n",
    "# tensor([0.2500, 0.4000, 0.5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dot(x, y)  # compute the scalar product of two vectors\n",
    "\n",
    "# OUTPUT\n",
    "# tensor(32.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dot(x, y).dim() # this is a 0D tensor or a scalar\n",
    "\n",
    "# OUTPUT\n",
    "# 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note how `torch.dot(x, y)` produces a scalar, yet this is still wrapped in a tensor\n",
    "# to get the raw scalar value, call .item() on the tensor. This is so pytorch can \n",
    "# track the operations applied to even scalar values.\n",
    "torch.dot(x, y).item()\n",
    "\n",
    "# OUTPUT\n",
    "# 32.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time For Educated Guesses!\n",
    "In this next section, see if you can work out what each are doing, and what you expect the output would be beforehand, before running the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.argmax()  # the index of the maximum element of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x = torch.arange(0, 9).reshape((3, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x @ y  # Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((2, 3, 1, 10, 10))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced PyTorch Operations\n",
    "\n",
    "Below are some more advanced operations that you will see in PyTorch but can represent important parts of networks and code.\n",
    "\n",
    "Once again, look at the comment and think about what the code will do before it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.squeeze().shape  # squeeze remove dimensions of size one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.unsqueeze(dim=4).shape  # unsqueeze adds a new dimension of size one at dimensional index `dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 100).reshape((2, 5, 10))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape((10, 10))  # We can squash any number of dimensions into one using reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping doesn't create new data, it produces a view on existing data,\n",
    "# if you update that data, you'll update the old tensors it came from.\n",
    "\n",
    "y = x.reshape((10, 10))\n",
    "y[0, 0] = 100\n",
    "print(y)\n",
    "print(x)  # notice that the data in x has changed too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've really on scratched the surface of the functionality provided PyTorch. Before implementing something yourself, it's always worth scanning through the documentation to check if PyTorch already provides an implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Building Your First Fully Connected Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've got to know the basics of pytorch, we can implement a 2-layer fully connected network (a.k.a MultiLayer Percepton) and train it using gradient descent.\n",
    "\n",
    "First we need to load in our data. You can use the following code that downloads and handles loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dataset_dir = Path.home() / \".cache\" / \"torch\" / \"datasets\"\n",
    "batch_size = 256\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "default_dataset_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `default_dataset_dir` is where we will save the CIFAR10 dataset, feel free to save this wherever you want.\n",
    "* `batch_size` is one of the more important hyperparameters (parameters that we set). This refers to how many instances we see per training loop.\n",
    "* `transform` is not something to worry about at this point, it's a function that gets applied to each example, in this case turning each image into a tensor.\n",
    "\n",
    "Finally, we make the dataset directory with the `mkdir` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    default_dataset_dir, train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    default_dataset_dir, train=False, download=False, transform=transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that's a lot of code, what is it all doing?\n",
    "\n",
    "`train_dataset` and `test_dataset` represent objects which load our training set and our testing set. These have been created for CIFAR10 for researchers to easily download and use it.\n",
    "\n",
    "The loaders, i.e. `train_loader` and `test_loader` This allows for us to easily access them in our training/testing loops (you will see this later) but is essentially just a wrapper around the dataset. They include some interesting parameters:\n",
    "* shuffle: whether to shuffle the items in the dataset, this is important for training as otherwise our model could overfit!\n",
    "* batch_size: Same as above, how many items we see per training loop\n",
    "Don't worry too much about the other parameters at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fully Connected Layer\n",
    "\n",
    "Now we need to create a fully connected layer that takes an input $x$, and trainable weights $W$ and biases $b$ and computes\n",
    "\n",
    "$$Wx + b$$\n",
    "\n",
    "PyTorch has a library of common layer types including a fully connected layer, its class name is `Linear` as the layer produces a linear transformation of the input data.\n",
    "\n",
    "We have a single fully connected layer, but we want to stack these to produce a neural network composed of two layers (a.k.a Multi-layer Perceptron or MLP):\n",
    "\n",
    "* Input size: 3,072 features\n",
    "* Hidden layer size: 100 units\n",
    "* Output size: 3 classes\n",
    "\n",
    "We need to put a non-linear function in between these two layers as otherwise the transformation is just as powerful in representational capacity as a linear classifier. We want to produce non-linear decision boundaries as these will better fit our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a MLP class that brings together 2 fully connected layers with a ReLU on the output of the first layer. We have done the first layer for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 hidden_layer_size: int,\n",
    "                 output_size: int,\n",
    "                 activation_fn: Callable[[torch.Tensor], torch.Tensor] = F.relu):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.l2 = None #Fill this in yourself\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.l1(inputs)\n",
    "        x = self.activation_fn(x)\n",
    "        x = None #Fill this in yourself\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deconstruct the signature of the `forward` method\n",
    "\n",
    "```python\n",
    "def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "    ...\n",
    "```\n",
    "\n",
    "`inputs: torch.Tensor` says that the parameter `inputs` is of type `torch.Tensor`. The return type of the method is denoted by `-> torch.Tensor` stating that the method returns a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a generic type `Callable` which defines the type of a function, it has the format `Callable[[args], return_type]`. `activation_fn: Callable[[torch.Tensor], torch.Tensor]` means that `activation_fn` should be a function that takes in a single argument of type `torch.Tensor` and returns a `torch.Tensor`. We've also defined the default value of this parameter to be `F.relu` which is the functional implementation of a rectified linear unit in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate the MLP class for our problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = 3072\n",
    "hidden_layer_size = 2000\n",
    "class_count = 10\n",
    "model = MLP(feature_count, hidden_layer_size, class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a think about these sizes, the feature count is the input, our images are 32x32, with 3 channels (red, green, and blue), therefore we have 3,072 inputs.\n",
    "\n",
    "The hidden layer size can be whatever we wish, we will start with 100, but it's something you can change later.\n",
    "\n",
    "Finally, the class count, which corresponds to our output, needs to be the same size as the number of classes in our dataset, which is 10 in this case.\n",
    "\n",
    "*What would happen if we increase the number of classes in our dataset?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "We'll now look into the training loop. This is a two-stage process:\n",
    "\n",
    "1. First, we pass through examples from our training set to get a prediction and compare this with what it *should* be, i.e. the ground truth\n",
    "2. Then, we update the network based on the difference between the prediction and the ground truth.\n",
    "\n",
    "We'll define a **loss function**, this is what we can use to compare our predicted values against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, labels in train_loader: #Get the inputs in a batch and the corresponding labels\n",
    "    \n",
    "    batch = batch.flatten(1) #This converts our images into greyscale and flattens them to be of size 1024 instead of 32x32\n",
    "    \n",
    "    logits = model(batch) #Get the output from the model\n",
    "    \n",
    "    loss = loss_function(logits, labels) #Calculate our loss, a value of how good (or bad) our network is doing\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the loss, this is a tensor, but it also has a grad_fn applied to it. This tells the network how to update the weights based on this value.\n",
    "We can use an optimiser to force the network to update, we first defined it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get introduced to a new hyperparameter, the learning rate (lr), which is one of the most important hyperparameters. If you want to change one hyperparameter, it will be this one!\n",
    "\n",
    "With the optimiser defined, we can now to a backward pass - or update the weights of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the loss before the update and the loss now, hopefully, this value should be lower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)\n",
    "print(loss_function(model(batch), labels))\n",
    "#The first value was our original loss, the second is the new one now that the model has been trained once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full training Loop\n",
    "\n",
    "We want to do more than a single training loop, so now we can put everything together.\n",
    "Using the code cells above, finish the training loop below and see if you can train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(feature_count, hidden_layer_size, class_count)\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Batch {i+1} out of 10')\n",
    "    for batch, labels in train_loader:\n",
    "        batch_size = batch.shape[0]\n",
    "        batch = batch.reshape(batch_size, -1)\n",
    "        \n",
    "        #Get the output logits from the model\n",
    " \n",
    "        #Calculate the loss\n",
    " \n",
    "        #Calculate the backward values of the loss\n",
    " \n",
    "        #Take a step of the optimiser\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
